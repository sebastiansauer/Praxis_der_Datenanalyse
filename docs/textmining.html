<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Statistik_21</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Ein Kurs in angewandter Statistik des beginnenden 21. Jahrhunderts">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Statistik_21" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Ein Kurs in angewandter Statistik des beginnenden 21. Jahrhunderts" />
  <meta name="github-repo" content="sebastiansauer/Statistik_21" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Statistik_21" />
  
  <meta name="twitter:description" content="Ein Kurs in angewandter Statistik des beginnenden 21. Jahrhunderts" />
  

<meta name="author" content="Sebastian Sauer">


<meta name="date" content="2017-02-13">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="klassifizierende-modelle.html">
<link rel="next" href="ergebnisse-kommunizieren.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Praxis der Datenanalyse</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Vorwort</a></li>
<li class="chapter" data-level="1" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html"><i class="fa fa-check"></i><b>1</b> Rahmen - Teil 1</a><ul>
<li class="chapter" data-level="1.1" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#software"><i class="fa fa-check"></i><b>1.1</b> Software</a><ul>
<li class="chapter" data-level="1.1.1" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#r-and-friends-installieren"><i class="fa fa-check"></i><b>1.1.1</b> R and Friends installieren</a></li>
<li class="chapter" data-level="1.1.2" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#hilfe-r-tut-nicht-so-wie-ich-das-will"><i class="fa fa-check"></i><b>1.1.2</b> Hilfe! R tut nicht so wie ich das will</a></li>
<li class="chapter" data-level="1.1.3" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#die-denk--und-gefuhlswelt-von-r"><i class="fa fa-check"></i><b>1.1.3</b> Die Denk- und Gefühlswelt von R</a></li>
<li class="chapter" data-level="1.1.4" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#pakete-installieren---beispiel-dplyr"><i class="fa fa-check"></i><b>1.1.4</b> Pakete installieren - Beispiel <code>dplyr</code></a></li>
<li class="chapter" data-level="1.1.5" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#r-pakete-fur-dieses-buch"><i class="fa fa-check"></i><b>1.1.5</b> R-Pakete für dieses Buch</a></li>
<li class="chapter" data-level="1.1.6" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#datensatze"><i class="fa fa-check"></i><b>1.1.6</b> Datensätze</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#bildnachweise"><i class="fa fa-check"></i><b>1.2</b> Bildnachweise</a></li>
<li class="chapter" data-level="1.3" data-path="rahmen-teil-1.html"><a href="rahmen-teil-1.html#was-ist-statistik-wozu-ist-sie-gut"><i class="fa fa-check"></i><b>1.3</b> Was ist Statistik? Wozu ist sie gut?</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tidy-data-daten-sauber-einlesen.html"><a href="tidy-data-daten-sauber-einlesen.html"><i class="fa fa-check"></i><b>2</b> Tidy Data - Daten sauber einlesen</a><ul>
<li class="chapter" data-level="2.1" data-path="tidy-data-daten-sauber-einlesen.html"><a href="tidy-data-daten-sauber-einlesen.html#daten-in-r-importieren"><i class="fa fa-check"></i><b>2.1</b> Daten in R importieren</a></li>
<li class="chapter" data-level="2.2" data-path="tidy-data-daten-sauber-einlesen.html"><a href="tidy-data-daten-sauber-einlesen.html#normalform-einer-tabelle"><i class="fa fa-check"></i><b>2.2</b> Normalform einer Tabelle</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html"><i class="fa fa-check"></i><b>3</b> Daten aufbereiten</a><ul>
<li class="chapter" data-level="3.1" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#typische-probleme"><i class="fa fa-check"></i><b>3.1</b> Typische Probleme</a></li>
<li class="chapter" data-level="3.2" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#daten-aufbereiten-mit-dplyr"><i class="fa fa-check"></i><b>3.2</b> Daten aufbereiten mit <code>dplyr</code></a><ul>
<li class="chapter" data-level="3.2.1" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#zeilen-filtern-mit-filter"><i class="fa fa-check"></i><b>3.2.1</b> Zeilen filtern mit <code>filter</code></a></li>
<li class="chapter" data-level="3.2.2" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#spalten-wahlen-mit-select"><i class="fa fa-check"></i><b>3.2.2</b> Spalten wählen mit <code>select</code></a></li>
<li class="chapter" data-level="3.2.3" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#zeilen-sortieren-mit-arrange"><i class="fa fa-check"></i><b>3.2.3</b> Zeilen sortieren mit <code>arrange</code></a></li>
<li class="chapter" data-level="3.2.4" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#datensatz-gruppieren-mit-group_by"><i class="fa fa-check"></i><b>3.2.4</b> Datensatz gruppieren mit <code>group_by</code></a></li>
<li class="chapter" data-level="3.2.5" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#eine-spalte-zusammenfassen-mit-summarise"><i class="fa fa-check"></i><b>3.2.5</b> Eine Spalte zusammenfassen mit <code>summarise</code></a></li>
<li class="chapter" data-level="3.2.6" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#zeilen-zahlen-mit-n-und-count"><i class="fa fa-check"></i><b>3.2.6</b> Zeilen zählen mit <code>n</code> und <code>count</code></a></li>
<li class="chapter" data-level="3.2.7" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#die-pfeife"><i class="fa fa-check"></i><b>3.2.7</b> Die Pfeife</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#fallstudie-nycflights13"><i class="fa fa-check"></i><b>3.3</b> Fallstudie <code>nycflights13</code></a></li>
<li class="chapter" data-level="3.4" data-path="daten-aufbereiten.html"><a href="daten-aufbereiten.html#weiterfuhrende-hinweise"><i class="fa fa-check"></i><b>3.4</b> Weiterführende Hinweise</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html"><i class="fa fa-check"></i><b>4</b> Daten visualisieren</a><ul>
<li class="chapter" data-level="4.1" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#haufige-arten-von-diagrammen"><i class="fa fa-check"></i><b>4.1</b> Häufige Arten von Diagrammen</a><ul>
<li class="chapter" data-level="4.1.1" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#eine-kontinuierliche-variable"><i class="fa fa-check"></i><b>4.1.1</b> Eine kontinuierliche Variable</a></li>
<li class="chapter" data-level="4.1.2" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#zwei-kontinuierliche-variablen"><i class="fa fa-check"></i><b>4.1.2</b> Zwei kontinuierliche Variablen</a></li>
<li class="chapter" data-level="4.1.3" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#eine-diskrete-variable"><i class="fa fa-check"></i><b>4.1.3</b> Eine diskrete Variable</a></li>
<li class="chapter" data-level="4.1.4" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#zwei-diskrete-variablen"><i class="fa fa-check"></i><b>4.1.4</b> Zwei diskrete Variablen</a></li>
<li class="chapter" data-level="4.1.5" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#zusammenfassungen-zeigen"><i class="fa fa-check"></i><b>4.1.5</b> Zusammenfassungen zeigen</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#farblehre"><i class="fa fa-check"></i><b>4.2</b> Farblehre</a></li>
<li class="chapter" data-level="4.3" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#prinzipien"><i class="fa fa-check"></i><b>4.3</b> Prinzipien</a></li>
<li class="chapter" data-level="4.4" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#erweiterungen-fur-ggplot"><i class="fa fa-check"></i><b>4.4</b> Erweiterungen für ggplot</a><ul>
<li class="chapter" data-level="4.4.1" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#ggpairs"><i class="fa fa-check"></i><b>4.4.1</b> ggpairs</a></li>
<li class="chapter" data-level="4.4.2" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#weitere"><i class="fa fa-check"></i><b>4.4.2</b> Weitere</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#fallstudie"><i class="fa fa-check"></i><b>4.5</b> Fallstudie</a><ul>
<li class="chapter" data-level="4.5.1" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#daten-einlesen"><i class="fa fa-check"></i><b>4.5.1</b> Daten einlesen</a></li>
<li class="chapter" data-level="4.5.2" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#daten-umstellen"><i class="fa fa-check"></i><b>4.5.2</b> Daten umstellen</a></li>
<li class="chapter" data-level="4.5.3" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#diagramme-fur-anteile"><i class="fa fa-check"></i><b>4.5.3</b> Diagramme für Anteile</a></li>
<li class="chapter" data-level="4.5.4" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#um-90-drehen"><i class="fa fa-check"></i><b>4.5.4</b> Um 90° drehen</a></li>
<li class="chapter" data-level="4.5.5" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#text-labels-fur-die-items"><i class="fa fa-check"></i><b>4.5.5</b> Text-Labels für die Items</a></li>
<li class="chapter" data-level="4.5.6" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#diagramm-mit-haufigkeiten"><i class="fa fa-check"></i><b>4.5.6</b> Diagramm mit Häufigkeiten</a></li>
<li class="chapter" data-level="4.5.7" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#farbschema"><i class="fa fa-check"></i><b>4.5.7</b> Farbschema</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="daten-visualisieren.html"><a href="daten-visualisieren.html#verweise"><i class="fa fa-check"></i><b>4.6</b> Verweise</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html"><i class="fa fa-check"></i><b>5</b> Statistisches Modellieren</a><ul>
<li class="chapter" data-level="5.1" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#Modellieren"><i class="fa fa-check"></i><b>5.1</b> Was ist ein Modell? Was ist Modellieren?</a><ul>
<li class="chapter" data-level="5.1.1" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#ziele-des-modellierens"><i class="fa fa-check"></i><b>5.1.1</b> Ziele des Modellierens</a></li>
<li class="chapter" data-level="5.1.2" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#parametrische-modelle-vs.non-parametrische-modelle"><i class="fa fa-check"></i><b>5.1.2</b> Parametrische Modelle vs. non-parametrische Modelle</a></li>
<li class="chapter" data-level="5.1.3" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#der-spagat-zwischen-prazision-und-streuung"><i class="fa fa-check"></i><b>5.1.3</b> Der Spagat zwischen Präzision und Streuung</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#der-p-wert"><i class="fa fa-check"></i><b>5.2</b> Der p-Wert</a></li>
<li class="chapter" data-level="5.3" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#uberanpassung"><i class="fa fa-check"></i><b>5.3</b> Überanpassung</a></li>
<li class="chapter" data-level="5.4" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#pradiktion-vs.explanation"><i class="fa fa-check"></i><b>5.4</b> Prädiktion vs. Explanation</a></li>
<li class="chapter" data-level="5.5" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#numerische-vs.klassifizierende-modelle"><i class="fa fa-check"></i><b>5.5</b> Numerische vs. klassifizierende Modelle</a></li>
<li class="chapter" data-level="5.6" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#geleitete-vs.ungeleitete-modelle"><i class="fa fa-check"></i><b>5.6</b> Geleitete vs. ungeleitete Modelle</a></li>
<li class="chapter" data-level="5.7" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#parametrische-vs.nichtparametrische-modelle"><i class="fa fa-check"></i><b>5.7</b> Parametrische vs. nichtparametrische Modelle</a></li>
<li class="chapter" data-level="5.8" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#fehler--vs.varianzreduktion"><i class="fa fa-check"></i><b>5.8</b> Fehler- vs. Varianzreduktion</a></li>
<li class="chapter" data-level="5.9" data-path="statistisches-modellieren.html"><a href="statistisches-modellieren.html#modellgute"><i class="fa fa-check"></i><b>5.9</b> Modellgüte</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="numerische-modelle.html"><a href="numerische-modelle.html"><i class="fa fa-check"></i><b>6</b> Numerische Modelle</a><ul>
<li class="chapter" data-level="6.1" data-path="numerische-modelle.html"><a href="numerische-modelle.html#lineare-regression"><i class="fa fa-check"></i><b>6.1</b> Lineare Regression</a><ul>
<li class="chapter" data-level="6.1.1" data-path="numerische-modelle.html"><a href="numerische-modelle.html#eine-kurze-geschichte-der-linearen-regression"><i class="fa fa-check"></i><b>6.1.1</b> Eine kurze Geschichte der linearen Regression</a></li>
<li class="chapter" data-level="6.1.2" data-path="numerische-modelle.html"><a href="numerische-modelle.html#die-lineare-regression-als-schweizer-taschenmesser"><i class="fa fa-check"></i><b>6.1.2</b> Die lineare Regression als Schweizer Taschenmesser</a></li>
<li class="chapter" data-level="6.1.3" data-path="numerische-modelle.html"><a href="numerische-modelle.html#interaktion-moderation"><i class="fa fa-check"></i><b>6.1.3</b> Interaktion/ Moderation</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="numerische-modelle.html"><a href="numerische-modelle.html#penalisierende-regression"><i class="fa fa-check"></i><b>6.2</b> Penalisierende Regression</a></li>
<li class="chapter" data-level="6.3" data-path="numerische-modelle.html"><a href="numerische-modelle.html#baumbasierte-verfahre"><i class="fa fa-check"></i><b>6.3</b> Baumbasierte Verfahre</a></li>
<li class="chapter" data-level="6.4" data-path="numerische-modelle.html"><a href="numerische-modelle.html#ausblick"><i class="fa fa-check"></i><b>6.4</b> Ausblick</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html"><i class="fa fa-check"></i><b>7</b> Klassifizierende Modelle</a><ul>
<li class="chapter" data-level="7.1" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html#clusteranalyse"><i class="fa fa-check"></i><b>7.1</b> Clusteranalyse</a></li>
<li class="chapter" data-level="7.2" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html#nachste-nachbarn-analyse"><i class="fa fa-check"></i><b>7.2</b> Nächste-Nachbarn-Analyse</a></li>
<li class="chapter" data-level="7.3" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html#hauptkomponenten-analyse"><i class="fa fa-check"></i><b>7.3</b> Hauptkomponenten-Analyse</a></li>
<li class="chapter" data-level="7.4" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html#fallstudie-uberleben-auf-der-titanic"><i class="fa fa-check"></i><b>7.4</b> Fallstudie: Überleben auf der Titanic</a><ul>
<li class="chapter" data-level="7.4.1" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html#daten-und-pakete-laden"><i class="fa fa-check"></i><b>7.4.1</b> Daten und Pakete laden</a></li>
<li class="chapter" data-level="7.4.2" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html#erster-blick"><i class="fa fa-check"></i><b>7.4.2</b> Erster Blick</a></li>
<li class="chapter" data-level="7.4.3" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html#welche-variablen-sind-interessant"><i class="fa fa-check"></i><b>7.4.3</b> Welche Variablen sind interessant?</a></li>
<li class="chapter" data-level="7.4.4" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html#univariate-haufigkeiten"><i class="fa fa-check"></i><b>7.4.4</b> Univariate Häufigkeiten</a></li>
<li class="chapter" data-level="7.4.5" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html#bivariate-haufigkeiten"><i class="fa fa-check"></i><b>7.4.5</b> Bivariate Häufigkeiten</a></li>
<li class="chapter" data-level="7.4.6" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html#signifikanztest"><i class="fa fa-check"></i><b>7.4.6</b> Signifikanztest</a></li>
<li class="chapter" data-level="7.4.7" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html#effektstarke"><i class="fa fa-check"></i><b>7.4.7</b> Effektstärke</a></li>
<li class="chapter" data-level="7.4.8" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html#logististische-regression"><i class="fa fa-check"></i><b>7.4.8</b> Logististische Regression</a></li>
<li class="chapter" data-level="7.4.9" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html#effektstarken-visualieren"><i class="fa fa-check"></i><b>7.4.9</b> Effektstärken visualieren</a></li>
<li class="chapter" data-level="7.4.10" data-path="klassifizierende-modelle.html"><a href="klassifizierende-modelle.html#fazit"><i class="fa fa-check"></i><b>7.4.10</b> Fazit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="textmining.html"><a href="textmining.html"><i class="fa fa-check"></i><b>8</b> Textmining</a><ul>
<li class="chapter" data-level="8.1" data-path="textmining.html"><a href="textmining.html#einfuhrung"><i class="fa fa-check"></i><b>8.1</b> Einführung</a><ul>
<li class="chapter" data-level="8.1.1" data-path="textmining.html"><a href="textmining.html#grundbegriffe"><i class="fa fa-check"></i><b>8.1.1</b> Grundbegriffe</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="textmining.html"><a href="textmining.html#grundlegende-analyse"><i class="fa fa-check"></i><b>8.2</b> Grundlegende Analyse</a><ul>
<li class="chapter" data-level="8.2.1" data-path="textmining.html"><a href="textmining.html#tidy-text-dataframes"><i class="fa fa-check"></i><b>8.2.1</b> Tidy Text Dataframes</a></li>
<li class="chapter" data-level="8.2.2" data-path="textmining.html"><a href="textmining.html#text-daten-einlesen"><i class="fa fa-check"></i><b>8.2.2</b> Text-Daten einlesen</a></li>
<li class="chapter" data-level="8.2.3" data-path="textmining.html"><a href="textmining.html#worthaufigkeiten-auszahlen"><i class="fa fa-check"></i><b>8.2.3</b> Worthäufigkeiten auszählen</a></li>
<li class="chapter" data-level="8.2.4" data-path="textmining.html"><a href="textmining.html#visualisierung"><i class="fa fa-check"></i><b>8.2.4</b> Visualisierung</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="textmining.html"><a href="textmining.html#sentiment-analyse"><i class="fa fa-check"></i><b>8.3</b> Sentiment-Analyse</a><ul>
<li class="chapter" data-level="8.3.1" data-path="textmining.html"><a href="textmining.html#ungewichtete-sentiment-analyse"><i class="fa fa-check"></i><b>8.3.1</b> Ungewichtete Sentiment-Analyse</a></li>
<li class="chapter" data-level="8.3.2" data-path="textmining.html"><a href="textmining.html#anzahl-der-unterschiedlichen-negativen-bzw.-positiven-worter"><i class="fa fa-check"></i><b>8.3.2</b> Anzahl der unterschiedlichen negativen bzw. positiven Wörter</a></li>
<li class="chapter" data-level="8.3.3" data-path="textmining.html"><a href="textmining.html#gewichtete-sentiment-analyse"><i class="fa fa-check"></i><b>8.3.3</b> Gewichtete Sentiment-Analyse</a></li>
<li class="chapter" data-level="8.3.4" data-path="textmining.html"><a href="textmining.html#tokens-mit-den-extremsten-sentimentwerten"><i class="fa fa-check"></i><b>8.3.4</b> Tokens mit den extremsten Sentimentwerten</a></li>
<li class="chapter" data-level="8.3.5" data-path="textmining.html"><a href="textmining.html#relativer-sentiments-wert"><i class="fa fa-check"></i><b>8.3.5</b> Relativer Sentiments-Wert</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="textmining.html"><a href="textmining.html#verknupfung-mit-anderen-variablen"><i class="fa fa-check"></i><b>8.4</b> Verknüpfung mit anderen Variablen</a></li>
<li class="chapter" data-level="8.5" data-path="textmining.html"><a href="textmining.html#vertiefung"><i class="fa fa-check"></i><b>8.5</b> Vertiefung</a><ul>
<li class="chapter" data-level="8.5.1" data-path="textmining.html"><a href="textmining.html#erstellung-des-sentiment-lexikons"><i class="fa fa-check"></i><b>8.5.1</b> Erstellung des Sentiment-Lexikons</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ergebnisse-kommunizieren.html"><a href="ergebnisse-kommunizieren.html"><i class="fa fa-check"></i><b>9</b> Ergebnisse kommunizieren</a><ul>
<li class="chapter" data-level="9.1" data-path="ergebnisse-kommunizieren.html"><a href="ergebnisse-kommunizieren.html#markdown-und-rmarkdown"><i class="fa fa-check"></i><b>9.1</b> Markdown und RMarkdown</a></li>
<li class="chapter" data-level="9.2" data-path="ergebnisse-kommunizieren.html"><a href="ergebnisse-kommunizieren.html#reproduzierbarkeit"><i class="fa fa-check"></i><b>9.2</b> Reproduzierbarkeit</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="rahmen-teil-2.html"><a href="rahmen-teil-2.html"><i class="fa fa-check"></i><b>10</b> Rahmen - Teil 2</a><ul>
<li class="chapter" data-level="10.1" data-path="rahmen-teil-2.html"><a href="rahmen-teil-2.html#trends"><i class="fa fa-check"></i><b>10.1</b> Trends</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistik_21</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="textmining" class="section level1">
<h1><span class="header-section-number">Kapitel 8</span> Textmining</h1>
<p>Ein großer Teil der zur Verfügung stehenden Daten liegt nicht als braves Zahlenmaterial vor, sondern in “unstrukturierter” Form, z.B. in Form von Texten. Im Gegensatz zur Analyse von numerischen Daten ist die Analyse von Texten<a href="#fn28" class="footnoteRef" id="fnref28"><sup>28</sup></a> weniger verbreitet bisher. In Anbetracht der Menge und der Informationsreichhaltigkeit von Text erscheint die Analyse von Text als vielversprechend.</p>
<p>In gewisser Weise ist das Textmining ein alternative zu klassischen qualitativen Verfahren der Sozialforschung. Geht es in der qualitativen Sozialforschung primär um das Verstehen eines Textes, so kann man für das Textmining ähnliche Ziele formulieren. Allerdings: Das Textmining ist wesentlich schwächer und beschränkter in der Tiefe des Verstehens. Der Computer ist einfach noch wesentlich <em>dümmer</em> als ein Mensch, in dieser Hinsicht. Allerdings ist er auch wesentlich <em>schneller</em> als ein Mensch, was das Lesen betrifft. Daher bietet sich das Textmining für das Lesen großer Textmengen an, in denen eine geringe Informationsdichte vermutet wird. Sozusagen maschinelles Sieben im großen Stil. Da fällt viel durch die Maschen, aber es werden Tonnen von Sand bewegt.</p>
<p>In der Regel wird das Textmining als <em>gemischte</em> Methode verwendet: sowohl qualitative als auch qualitative Aspekte spielen eine Rolle. Damit vermittelt das Textmining auf konstruktive Art und Weise zwischen den manchmal antagonierenden Schulen der qualitativ-idiographischen und der quantitativ-nomothetischen Sichtweise auf die Welt. Man könnte es auch als qualitative Forschung mit moderner Technik bezeichnen - mit den skizzierten Einschränkungen wohlgemerkt.</p>
<div id="einfuhrung" class="section level2">
<h2><span class="header-section-number">8.1</span> Einführung</h2>
<div id="grundbegriffe" class="section level3">
<h3><span class="header-section-number">8.1.1</span> Grundbegriffe</h3>
<p>Die computergestützte Analyse von Texten speiste (und speist) sich reichhaltig aus Quellen der Linguistik; entsprechende Fachtermini finden Verwendung:</p>
<ul>
<li><p>Ein <em>Corpus</em> bezeichnet die Menge der zu analyisierenden Dokumente; das könnten z.B. alle Reden der Bundeskanzlerin Angela Merkel sein oder alle Tweets von “@realDonaldTrump”.</p></li>
<li><p>Ein <em>Token</em> (<em>Term</em>) ist ein elementarer Baustein eines Texts, die kleinste Analyseeinheit, häufig ein Wort.</p></li>
<li><p>Unter <em>tidy text</em> versteht man einen Dataframe, in dem pro Zeile nur ein Term steht <span class="citation">(Silge and Robinson <a href="#ref-Silge2016">2016</a>)</span>.</p></li>
</ul>
</div>
</div>
<div id="grundlegende-analyse" class="section level2">
<h2><span class="header-section-number">8.2</span> Grundlegende Analyse</h2>
<div id="tidy-text-dataframes" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Tidy Text Dataframes</h3>
<p>Basteln wir uns einen <em>tidy text</em> Dataframe. Wir gehen dabei von einem Vektor mit mehreren Text-Elementen aus, das ist ein realistischer Startpunkt. Unser Text-Vektor<a href="#fn29" class="footnoteRef" id="fnref29"><sup>29</sup></a> besteht aus 4 Elementen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">text &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Wir haben die Frauen zu Bett gebracht,&quot;</span>,
          <span class="st">&quot;als die Männer in Frankreich standen.&quot;</span>,
          <span class="st">&quot;Wir hatten uns das viel schöner gedacht.&quot;</span>,
          <span class="st">&quot;Wir waren nur Konfirmanden.&quot;</span>)</code></pre></div>
<p>Als nächstes machen wir daraus einen Dataframe.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
text_df &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">Zeile =</span> <span class="dv">1</span>:<span class="dv">4</span>,
                      text)</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">Zeile</th>
<th align="left">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left">Wir haben die Frauen zu Bett gebracht,</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="left">als die Männer in Frankreich standen.</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="left">Wir hatten uns das viel schöner gedacht.</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="left">Wir waren nur Konfirmanden.</td>
</tr>
</tbody>
</table>
<p>Und “dehnen” diesen Dataframe zu einem <em>tidy text</em> Dataframe.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidytext)

text_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">unnest_tokens</span>(wort, text)
<span class="co">#&gt; # A tibble: 24 × 2</span>
<span class="co">#&gt;   Zeile  wort</span>
<span class="co">#&gt;   &lt;int&gt; &lt;chr&gt;</span>
<span class="co">#&gt; 1     1   wir</span>
<span class="co">#&gt; 2     1 haben</span>
<span class="co">#&gt; 3     1   die</span>
<span class="co">#&gt; # ... with 21 more rows</span></code></pre></div>
<p>Das <code>unnest_tokens</code> kann übersetzt werden als “entschachtele” oder “dehne” die Tokens - so dass in jeder Zeile nur noch ein Wort (Token) steht. Die Syntax ist <code>unnest_tokens(Ausgabespalte, Eingabespalte)</code>. Nebenbei werden übrigens alle Buchstaben auf Kleinschreibung getrimmt.</p>
<p>Als nächstes filtern wir die Satzzeichen heraus, da die Wörter für die Analyse wichtiger (oder zumindest einfacher) sind.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(stringr)

text_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">unnest_tokens</span>(wort, text) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(wort, <span class="st">&quot;[a-z]&quot;</span>))
<span class="co">#&gt; # A tibble: 24 × 2</span>
<span class="co">#&gt;   Zeile  wort</span>
<span class="co">#&gt;   &lt;int&gt; &lt;chr&gt;</span>
<span class="co">#&gt; 1     1   wir</span>
<span class="co">#&gt; 2     1 haben</span>
<span class="co">#&gt; 3     1   die</span>
<span class="co">#&gt; # ... with 21 more rows</span></code></pre></div>
</div>
<div id="text-daten-einlesen" class="section level3">
<h3><span class="header-section-number">8.2.2</span> Text-Daten einlesen</h3>
<p>Nun lesen wir Text-Daten ein; das können beliebige Daten sein. Eine gewisse Reichhaltigkeit ist von Vorteil. Nehmen wir das Parteiprogramm der Partei AfD<a href="#fn30" class="footnoteRef" id="fnref30"><sup>30</sup></a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pdftools)
<span class="kw">library</span>(downloader)

afd_url &lt;-<span class="st"> &quot;https://www.alternativefuer.de/wp-content/uploads/sites/7/2016/05/2016-06-27_afd-grundsatzprogramm_web-version.pdf&quot;</span>

afd_pfad &lt;-<span class="st"> &quot;data/afd_programm.pdf&quot;</span>

<span class="kw">download</span>(afd_url, afd_pfad)

afd_raw &lt;-<span class="st"> </span><span class="kw">pdf_text</span>(afd_pfad)

afd_raw[<span class="dv">3</span>]
<span class="co">#&gt; [1] &quot;3\t Programm für Deutschland | Inhalt\n   7 | Kultur, Sprache und Identität\t\t\t\t                                   45 9 | Einwanderung, Integration und Asyl\t\t\t                       57\n     7.1 \t\t Deutsche Kultur, Sprache und Identität erhalten\t               47   9.1\t Keine irreguläre Einwanderung über das Asylrecht\t        59\n     7.2 \t\t Deutsche Leitkultur statt Multikulturalismus\t\t                 47   9.1.1\t Asylzuwanderung - für einen Paradigmenwechsel\t         59\n     7.3 \t\t Die deutsche Sprache als Zentrum unserer Identität\t            47   9.1.2\t Rückführung - Schluss mit Fehlanreizen und \t\t\t\n     7.4 \t \t Kultur und Kunst von Einflussnahme der Parteien befreien\t     48 \t\t       falscher Nachsicht\t\t\t\t\t                                60\n     7.5 \t\t Für eine zeitgemäße Medienpolitik: Rundfunkbeitrag abschaffen\t 48   9.2\t Einwanderung aus EU-Staaten\t\t\t\t                          61\n     7.6 \t\t Der Islam im Spannungsverhältnis zu unserer Werteordnung\t      48   9.3\t Gesteuerte Einwanderung aus Drittstaaten\t\t               62\n     7.6.1\t\t Der Islam gehört nicht zu Deutschland\t\t\t                      49   9.4\t Integration - Mehr als nur Deutsch lernen\t\t              63\n     7.6.2\t\t Kritik am Islam muss erlaubt sein\t\t\t                          49   9.5\t Kosten der Einwanderung - Transparenz herstellen\t        63\n     7.6.3\t\t Auslandsfinanzierung von Moscheen beenden\t \t                  49   9.6\t Einwandererkriminalität - nichts verschleiern,\n     7.6.4\t\t Keine öffentlich-rechtliche Körperschaft für                     \t\t       nichts verschweigen\t\t\t\t\t                               64\n     \t\t\t      islamische Organisationen\t\t\t\t                                50   9.7\t Einbürgerung - Abschluss gelungener Integration\t         65\n     7.6.5\t\t Keine Vollverschleierung im öffentlichen Raum\t                50\n                                                                              10 | Wirtschaft, digitale Welt und Verbraucherschutz\t           66\n   8 | Schule, Hochschule und Forschung\t\t\t                                 51   10.1\t\t Freier Wettbewerb sichert unseren Wohlstand\t\t          67\n     8.1 \t\t Forschung und Lehre: In Freiheit und als Einheit\t              52   10.2 \t\t Soziale Marktwirtschaft statt Planwirtschaft\t\t        67\n     8.1.1\t \t Autonomie durch Grundfinanzierung stärken\t \t                 52   10.3 \t\t Internationale Wirtschaftspolitik neu ausrichten\t     67\n     8.1.2\t\t Förderung der “Gender-Forschung” beenden\t\t                    52   10.4 \t\t Hohe Standards für Handelsabkommen\t\t                  68\n     8.1.3\t\t Diplom, Magister und Staatsexamen wieder einführen\t           52   10.5 \t\t Bürokratie abbauen\t\t\t\t\t                               68\n     8.1.4\t\t Studienanforderungen erhöhen\t\t\t                               53   10.6 \t\t Den Technologiestandort Deutschland voranbringen\t     68\n     8.2 \t\t Unser Schulsystem: Stark durch Differenzierung\t                53   10.7 \t\t Staatliche Subventionen reduzieren und befristen\t     69\n     8.2.1\t\t Die Einheitsschule führt zu Qualitätsverlust\t\t                53   10.8 \t\t Keine Privatisierung gegen den Willen der Bürger\t     69\n     8.2.2\t\t Wissensvermittlung muss zentrales Anliegen bleiben\t           53   10.9 \t\t Der Mittelstand als Herz unserer Wirtschaftskraft\t    69\n     8.2.3\t\t Leistungsbereitschaft und Disziplin stärken\t\t                 54   10.10 \tDigitalisierung als Chance und Herausforderung\t        69\n     8.2.4\t\t Politisch-ideologische Indoktrination darf es an                   10.10.1 Quelloffene Software und sichere Hardware\t\t           69\n   \t\t\t der Schule nicht geben\t\t\t\t\t                                         54   10.10.2 Sichere Kommunikation als Standortvorteil\n     8.2.5\t\t Duale berufliche Bildung stärken und erhalten\t \t              54 \t\t          und Bürgerrecht\t\t\t\t\t                                70\n     8.2.6\t\t Keine Inklusion “um jeden Preis”. Förder- und                      10.10.3 Deutsche Literatur im Inland digitalisieren\t\t         70\n     \t\t\t      Sonderschulen erhalten\t\t\t\t                                   54   10.11\t\t Verbraucherschutz modernisieren und stärken\t\t         70\n     8.2.7 \t\t Koranschulen schließen. Islamkunde in den                         10.11.1 Lebensmittel besser kennzeichnen\t\t\t                   71\n     \t\t\t      Ethikunterricht integrieren\t\t\t\t                              55   10.11.2 Langlebige Produkte statt geplante Obsoleszenz\t       71\n     8.2.8 \t Keine Sonderrechte für muslimische Schüler\t\t                  55   10.11.3 Textilien und Kinderspielzeug auf Schadstoffe prüfen\t 71\n     8.3 \t\t Nein zu “Gender-Mainstreaming” und                                  10.11.4 Wasseraufbereitung modernisieren und verbessern\t      71\n   \t\t\t        Frühsexualisierung\t\t\t\t\t                                      55\n     8.3.1 \t\t Keine “geschlechterneutrale” Umgestaltung der\n     \t\t\t      deutschen Sprache\t\t\t\t\t                                       55\n     8.3.2 \t Geschlechterquoten sind leistungsfeindlich\n   \t\t\t        und ungerecht\t\t\t\t\t\t                                          56\n&quot;</span></code></pre></div>
<p>Mit <code>download</code> haben wir die Datei mit der Url <code>afd_url</code> heruntergeladen und als <code>afd_pfad</code> gespeichert. Für uns ist <code>pdf_text</code> sehr praktisch, da diese Funktion Text aus einer beliebige PDF-Datei in einen Text-Vektor einliest.</p>
<p>Der Vektor <code>afd_raw</code> hat 96 Elemente; zählen wir die Gesamtzahl an Wörtern. Dazu wandeln wir den Vektor in einen tidy text Dataframe um. Auch die Stopwörter entfernen wir wieder wie gehabt.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
afd_df &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">Zeile =</span> <span class="dv">1</span>:<span class="dv">96</span>, 
                     afd_raw)


afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">unnest_tokens</span>(token, afd_raw) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(token, <span class="st">&quot;[a-z]&quot;</span>)) -&gt;<span class="st"> </span>afd_df

<span class="kw">count</span>(afd_df) 
<span class="co">#&gt; # A tibble: 1 × 1</span>
<span class="co">#&gt;       n</span>
<span class="co">#&gt;   &lt;int&gt;</span>
<span class="co">#&gt; 1 26396</span></code></pre></div>
<p>Eine substanzielle Menge von Text. Was wohl die häufigsten Wörter sind?</p>
</div>
<div id="worthaufigkeiten-auszahlen" class="section level3">
<h3><span class="header-section-number">8.2.3</span> Worthäufigkeiten auszählen</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">na.omit</span>() %&gt;%<span class="st">  </span><span class="co"># fehlende Werte löschen</span>
<span class="st">  </span><span class="kw">count</span>(token, <span class="dt">sort =</span> <span class="ot">TRUE</span>)
<span class="co">#&gt; # A tibble: 7,087 × 2</span>
<span class="co">#&gt;   token     n</span>
<span class="co">#&gt;   &lt;chr&gt; &lt;int&gt;</span>
<span class="co">#&gt; 1   die  1151</span>
<span class="co">#&gt; 2   und  1147</span>
<span class="co">#&gt; 3   der   870</span>
<span class="co">#&gt; # ... with 7,084 more rows</span></code></pre></div>
<p>Die häufigsten Wörter sind inhaltsleere Partikel, Präpositionen, Artikel… Solche sogenannten “Stopwörter” sollten wir besser herausfischen, um zu den inhaltlich tragenden Wörtern zu kommen. Praktischerweise gibt es frei verfügbare Listen von Stopwörtern, z.B. im Paket <code>lsa</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lsa)
<span class="kw">data</span>(stopwords_de)

stopwords_de &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">word =</span> stopwords_de)

stopwords_de &lt;-<span class="st"> </span>stopwords_de %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">token =</span> word)

afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">anti_join</span>(stopwords_de) -&gt;<span class="st"> </span>afd_df</code></pre></div>
<p>Unser Datensatz hat jetzt viel weniger Zeilen; wir haben also durch <code>anti_join</code> Zeilen gelöscht (herausgefiltert). Das ist die Funktion von <code>anti_join</code>: Die Zeilen, die in beiden Dataframes vorkommen, werden herausgefiltert. Es verbleiben also nicht “Nicht-Stopwörter” in unserem Dataframe. Damit wird es schon interessanter, welche Wörter häufig sind.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">count</span>(token, <span class="dt">sort =</span> <span class="ot">TRUE</span>) -&gt;<span class="st"> </span>afd_count

afd_count %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">top_n</span>(<span class="dv">10</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span>knitr::<span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">token</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">deutschland</td>
<td align="right">190</td>
</tr>
<tr class="even">
<td align="left">afd</td>
<td align="right">171</td>
</tr>
<tr class="odd">
<td align="left">programm</td>
<td align="right">80</td>
</tr>
<tr class="even">
<td align="left">wollen</td>
<td align="right">67</td>
</tr>
<tr class="odd">
<td align="left">bürger</td>
<td align="right">57</td>
</tr>
<tr class="even">
<td align="left">euro</td>
<td align="right">55</td>
</tr>
<tr class="odd">
<td align="left">dafür</td>
<td align="right">53</td>
</tr>
<tr class="even">
<td align="left">eu</td>
<td align="right">53</td>
</tr>
<tr class="odd">
<td align="left">deutsche</td>
<td align="right">47</td>
</tr>
<tr class="even">
<td align="left">deutschen</td>
<td align="right">47</td>
</tr>
</tbody>
</table>
<p>Ganz interessant; aber es gibt mehrere Varianten des Themas “deutsch”. Es ist wohl sinnvoller, diese auf den gemeinsamen Wortstamm zurückzuführen und diesen nur einmal zu zählen. Dieses Verfahren nennt man “stemming” oder trunkieren.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(SnowballC)

afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">token_stem =</span> <span class="kw">wordStem</span>(.$token, <span class="dt">language =</span> <span class="st">&quot;german&quot;</span>)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">count</span>(token_stem, <span class="dt">sort =</span> <span class="ot">TRUE</span>) -&gt;<span class="st"> </span>afd_count

afd_count %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">top_n</span>(<span class="dv">10</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span>knitr::<span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">token_stem</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">deutschland</td>
<td align="right">219</td>
</tr>
<tr class="even">
<td align="left">afd</td>
<td align="right">171</td>
</tr>
<tr class="odd">
<td align="left">deutsch</td>
<td align="right">119</td>
</tr>
<tr class="even">
<td align="left">polit</td>
<td align="right">88</td>
</tr>
<tr class="odd">
<td align="left">staat</td>
<td align="right">85</td>
</tr>
<tr class="even">
<td align="left">programm</td>
<td align="right">81</td>
</tr>
<tr class="odd">
<td align="left">europa</td>
<td align="right">80</td>
</tr>
<tr class="even">
<td align="left">woll</td>
<td align="right">67</td>
</tr>
<tr class="odd">
<td align="left">burg</td>
<td align="right">66</td>
</tr>
<tr class="even">
<td align="left">soll</td>
<td align="right">63</td>
</tr>
</tbody>
</table>
<p>Das ist schon informativer. Dem Befehl <code>wordStem</code> füttert man einen Vektor an Wörtern ein und gibt die Sprache an (Default ist Englisch<a href="#fn31" class="footnoteRef" id="fnref31"><sup>31</sup></a>). Das ist schon alles.</p>
</div>
<div id="visualisierung" class="section level3">
<h3><span class="header-section-number">8.2.4</span> Visualisierung</h3>
<p>Zum Abschluss noch eine Visualisierung mit einer “Wordcloud” dazu.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(wordcloud)
<span class="kw">wordcloud</span>(<span class="dt">words =</span> afd_count$token_stem, <span class="dt">freq =</span> afd_count$n, <span class="dt">max.words =</span> <span class="dv">100</span>, <span class="dt">scale =</span> <span class="kw">c</span>(<span class="dv">2</span>,.<span class="dv">5</span>), <span class="dt">colors=</span><span class="kw">brewer.pal</span>(<span class="dv">6</span>, <span class="st">&quot;Dark2&quot;</span>))</code></pre></div>
<p><img src="09_Textmining_files/figure-html/unnamed-chunk-13-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Man kann die Anzahl der Wörter, Farben und einige weitere Formatierungen der Wortwolke beeinflussen<a href="#fn32" class="footnoteRef" id="fnref32"><sup>32</sup></a>.</p>
<p>Weniger verspielt ist eine schlichte visualisierte Häufigkeitsauszählung dieser Art.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
afd_count %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">top_n</span>(<span class="dv">30</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() +
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">reorder</span>(token_stem, n), <span class="dt">y =</span> n) +
<span class="st">  </span><span class="kw">geom_col</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;mit Trunkierung&quot;</span>) +
<span class="st">  </span><span class="kw">coord_flip</span>() -&gt;<span class="st"> </span>p1

afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">count</span>(token, <span class="dt">sort =</span> <span class="ot">TRUE</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">top_n</span>(<span class="dv">30</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() +
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">reorder</span>(token, n), <span class="dt">y =</span> n) +
<span class="st">  </span><span class="kw">geom_col</span>() +
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;ohne Trunkierung&quot;</span>) +
<span class="st">  </span><span class="kw">coord_flip</span>() -&gt;<span class="st"> </span>p2


<span class="kw">library</span>(gridExtra)
<span class="kw">grid.arrange</span>(p1, p2, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="09_Textmining_files/figure-html/unnamed-chunk-14-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Die beiden Diagramme vergleichen die trunkierten Wörter mit den nicht trunktierten Wörtern. Mit <code>reorder</code> ordnen wir die Spalte <code>token</code> nach der Spalte <code>n</code>. <code>coord_flip</code> dreht die Abbildung um 90°, d.h. die Achsen sind vertauscht. <code>grid.arrange</code> packt beide Plots in eine Abbildung, welche 2 Spalten (<code>ncol</code>) hat.</p>
</div>
</div>
<div id="sentiment-analyse" class="section level2">
<h2><span class="header-section-number">8.3</span> Sentiment-Analyse</h2>
<p>Eine weitere interessante Analyse ist, die “Stimmung” oder “Emotionen” (Sentiments) eines Textes auszulesen. Die Anführungszeichen deuten an, dass hier ein Maß an Verständnis suggeriert wird, welches nicht (unbedingt) von der Analyse eingehalten wird. Jedenfalls ist das Prinzip der Sentiment-Analyse im einfachsten Fall so:</p>
<blockquote>
<p>Schau dir jeden Token aus dem Text an.<br />
Prüfe, ob sich das Wort im Lexikon der Sentiments wiederfindet.<br />
Wenn ja, dann addiere den Sentimentswert dieses Tokens zum bestehenden Sentiments-Wert.<br />
Wenn nein, dann gehe weiter zum nächsten Wort.<br />
Liefere zum Schluss die Summenwerte pro Sentiment zurück.</p>
</blockquote>
<p>Es gibt Sentiment-Lexika, die lediglich einen Punkt für “positive Konnotation” bzw. “negative Konnotation” geben; andere Lexiko weisen differenzierte Gefühlskonnotationen auf. Wir nutzen hier <a href="http://asv.informatik.uni-leipzig.de/download/sentiws.html">dieses</a> Lexikon <span class="citation">(Remus, Quasthoff, and Heyer <a href="#ref-remquahey2010">2010</a>)</span>. Der Einfachheit halber gehen wir im Folgenden davon aus, dass das Lexikon schon aufbereitet vorliegt. Die Aufbereitung unten im Abschnitt zur Vertiefung nachgelesen werden.</p>
<p>Unser Sentiment-Lexikon sieht so aus:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(knitr)

<span class="kw">kable</span>(<span class="kw">head</span>(sentiment_df))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">neg_pos</th>
<th align="left">Wort</th>
<th align="right">Wert</th>
<th align="left">Inflektionen</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">neg</td>
<td align="left">Abbau</td>
<td align="right">-0.058</td>
<td align="left">Abbaus,Abbaues,Abbauen,Abbaue</td>
</tr>
<tr class="even">
<td align="left">neg</td>
<td align="left">Abbruch</td>
<td align="right">-0.005</td>
<td align="left">Abbruches,Abbrüche,Abbruchs,Abbrüchen</td>
</tr>
<tr class="odd">
<td align="left">neg</td>
<td align="left">Abdankung</td>
<td align="right">-0.005</td>
<td align="left">Abdankungen</td>
</tr>
<tr class="even">
<td align="left">neg</td>
<td align="left">Abdämpfung</td>
<td align="right">-0.005</td>
<td align="left">Abdämpfungen</td>
</tr>
<tr class="odd">
<td align="left">neg</td>
<td align="left">Abfall</td>
<td align="right">-0.005</td>
<td align="left">Abfalles,Abfälle,Abfalls,Abfällen</td>
</tr>
<tr class="even">
<td align="left">neg</td>
<td align="left">Abfuhr</td>
<td align="right">-0.337</td>
<td align="left">Abfuhren</td>
</tr>
</tbody>
</table>
<div id="ungewichtete-sentiment-analyse" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Ungewichtete Sentiment-Analyse</h3>
<p>Nun können wir jedes Token des Textes mit dem Sentiment-Lexikon abgleichen; dabei zählen wir die Treffer für positive bzw. negative Terme. Besser wäre noch: Wir könnten die Sentiment-Werte pro Treffer addieren (und nicht für jeden Term 1 addieren). Aber das heben wir uns für später auf.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sentiment_neg &lt;-<span class="st"> </span><span class="kw">match</span>(afd_df$token, <span class="kw">filter</span>(sentiment_df, neg_pos ==<span class="st"> &quot;neg&quot;</span>)$Wort)
neg_score &lt;-<span class="st"> </span><span class="kw">sum</span>(!<span class="kw">is.na</span>(sentiment_neg))

sentiment_pos &lt;-<span class="st"> </span><span class="kw">match</span>(afd_df$token, <span class="kw">filter</span>(sentiment_df, neg_pos ==<span class="st"> &quot;pos&quot;</span>)$Wort)
pos_score &lt;-<span class="st"> </span><span class="kw">sum</span>(!<span class="kw">is.na</span>(sentiment_pos))

<span class="kw">round</span>(pos_score/neg_score, <span class="dv">1</span>)
<span class="co">#&gt; [1] 2.7</span></code></pre></div>
<p>Hier schauen wir für jedes negative (positive) Token, ob es einen “Match” im Sentiment-Lexikon (<code>sentiment_df$Wort</code>) gibt; das geht mit <code>match</code>. <code>match</code> liefert <code>NA</code> zurück, wenn es keinen Match gibt (ansonsten die Nummer des Sentiment-Worts). Wir brauchen also nur die Anzahl der Nicht-Nas (<code>!is.na</code>) auszuzählen, um die Anzahl der Matches zu bekommen.</p>
<p>Entgegen dem, was man vielleicht erwarten würde, ist der Text offenbar positiv geprägt. Der “Positiv-Wert” ist ca. 2.6 mal so groß wie der “Negativ-Wert”. Fragt sich, wie sich dieser Wert mit anderen vergleichbaren Texten (z.B. andere Parteien) misst. Hier sei noch einmal betont, dass die Sentiment-Analyse bestenfalls grobe Abschätzungen liefern kann und keinesfalls sich zu einem hermeneutischen Verständnis aufschwingt.</p>
<p>Welche negativen Wörter und welche positiven Wörter wurden wohl verwendet? Schauen wir uns ein paar an.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sentiment_neg =</span> sentiment_neg,
         <span class="dt">sentiment_pos =</span> sentiment_pos) -&gt;<span class="st"> </span>afd_df

afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(sentiment_neg)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(token) -&gt;<span class="st"> </span>negative_sentiments
  
<span class="kw">head</span>(negative_sentiments$token,<span class="dv">50</span>)
<span class="co">#&gt;  [1] &quot;mindern&quot;       &quot;verbieten&quot;     &quot;unmöglich&quot;     &quot;töten&quot;        </span>
<span class="co">#&gt;  [5] &quot;träge&quot;         &quot;schädlich&quot;     &quot;unangemessen&quot;  &quot;unterlassen&quot;  </span>
<span class="co">#&gt;  [9] &quot;kalt&quot;          &quot;schwächen&quot;     &quot;ausfallen&quot;     &quot;verringern&quot;   </span>
<span class="co">#&gt; [13] &quot;verringern&quot;    &quot;verringern&quot;    &quot;verringern&quot;    &quot;belasten&quot;     </span>
<span class="co">#&gt; [17] &quot;belasten&quot;      &quot;fremd&quot;         &quot;schädigenden&quot;  &quot;klein&quot;        </span>
<span class="co">#&gt; [21] &quot;klein&quot;         &quot;klein&quot;         &quot;klein&quot;         &quot;eingeschränkt&quot;</span>
<span class="co">#&gt; [25] &quot;eingeschränkt&quot; &quot;entziehen&quot;     &quot;schwer&quot;        &quot;schwer&quot;       </span>
<span class="co">#&gt; [29] &quot;schwer&quot;        &quot;schwer&quot;        &quot;verharmlosen&quot;  &quot;unerwünscht&quot;  </span>
<span class="co">#&gt; [33] &quot;abgleiten&quot;     &quot;wirkungslos&quot;   &quot;schwach&quot;       &quot;verschleppen&quot; </span>
<span class="co">#&gt; [37] &quot;vermindern&quot;    &quot;vermindern&quot;    &quot;ungleich&quot;      &quot;widersprechen&quot;</span>
<span class="co">#&gt; [41] &quot;zerstört&quot;      &quot;zerstört&quot;      &quot;erschweren&quot;    &quot;auffallen&quot;    </span>
<span class="co">#&gt; [45] &quot;unvereinbar&quot;   &quot;unvereinbar&quot;   &quot;unvereinbar&quot;   &quot;abhängig&quot;     </span>
<span class="co">#&gt; [49] &quot;abhängig&quot;      &quot;abhängig&quot;</span>


afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(sentiment_pos)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(token) -&gt;<span class="st"> </span>positive_sentiments

<span class="kw">head</span>(positive_sentiments$token, <span class="dv">50</span>)
<span class="co">#&gt;  [1] &quot;optimal&quot;         &quot;aufstocken&quot;      &quot;locker&quot;         </span>
<span class="co">#&gt;  [4] &quot;zulässig&quot;        &quot;gleichwertig&quot;    &quot;wiederbeleben&quot;  </span>
<span class="co">#&gt;  [7] &quot;beauftragen&quot;     &quot;wertvoll&quot;        &quot;nah&quot;            </span>
<span class="co">#&gt; [10] &quot;nah&quot;             &quot;nah&quot;             &quot;überzeugt&quot;      </span>
<span class="co">#&gt; [13] &quot;genehmigen&quot;      &quot;genehmigen&quot;      &quot;überleben&quot;      </span>
<span class="co">#&gt; [16] &quot;überleben&quot;       &quot;genau&quot;           &quot;verständlich&quot;   </span>
<span class="co">#&gt; [19] &quot;erlauben&quot;        &quot;aufbereiten&quot;     &quot;zugänglich&quot;     </span>
<span class="co">#&gt; [22] &quot;messbar&quot;         &quot;erzeugen&quot;        &quot;erzeugen&quot;       </span>
<span class="co">#&gt; [25] &quot;ausgleichen&quot;     &quot;ausreichen&quot;      &quot;mögen&quot;          </span>
<span class="co">#&gt; [28] &quot;kostengünstig&quot;   &quot;gestiegen&quot;       &quot;gestiegen&quot;      </span>
<span class="co">#&gt; [31] &quot;bedeuten&quot;        &quot;massiv&quot;          &quot;massiv&quot;         </span>
<span class="co">#&gt; [34] &quot;massiv&quot;          &quot;massiv&quot;          &quot;einfach&quot;        </span>
<span class="co">#&gt; [37] &quot;finanzieren&quot;     &quot;vertraulich&quot;     &quot;steigen&quot;        </span>
<span class="co">#&gt; [40] &quot;erweitern&quot;       &quot;verstehen&quot;       &quot;schnell&quot;        </span>
<span class="co">#&gt; [43] &quot;zugreifen&quot;       &quot;tätig&quot;           &quot;unternehmerisch&quot;</span>
<span class="co">#&gt; [46] &quot;entlasten&quot;       &quot;entlasten&quot;       &quot;entlasten&quot;      </span>
<span class="co">#&gt; [49] &quot;entlasten&quot;       &quot;helfen&quot;</span></code></pre></div>
</div>
<div id="anzahl-der-unterschiedlichen-negativen-bzw.-positiven-worter" class="section level3">
<h3><span class="header-section-number">8.3.2</span> Anzahl der unterschiedlichen negativen bzw. positiven Wörter</h3>
<p>Allerdings müssen wir unterscheiden zwischen der <em>Anzahl</em> der negativen bzw. positiven Wörtern und der Anzahl der <em>unterschiedlichen</em> Wörter.</p>
<p>Zählen wir noch die Anzahl der unterschiedlichen Wörter im negativen und positiven Fall.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(sentiment_neg)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">n_distinct_neg =</span> <span class="kw">n_distinct</span>(token))
<span class="co">#&gt; # A tibble: 1 × 1</span>
<span class="co">#&gt;   n_distinct_neg</span>
<span class="co">#&gt;            &lt;int&gt;</span>
<span class="co">#&gt; 1             96</span>


afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(sentiment_pos)) %&gt;%<span class="st"> </span>
<span class="st">    </span><span class="kw">summarise</span>(<span class="dt">n_distinct_pos =</span> <span class="kw">n_distinct</span>(token))
<span class="co">#&gt; # A tibble: 1 × 1</span>
<span class="co">#&gt;   n_distinct_pos</span>
<span class="co">#&gt;            &lt;int&gt;</span>
<span class="co">#&gt; 1            187</span></code></pre></div>
<p>Dieses Ergebnis passt zum vorherigen: Die Anzahl der positiven Wörter (187) ist ca. doppelt so groß wie die Anzahl der negativen Wörter (96).</p>
</div>
<div id="gewichtete-sentiment-analyse" class="section level3">
<h3><span class="header-section-number">8.3.3</span> Gewichtete Sentiment-Analyse</h3>
<p>Oben haben wir nur ausgezählt, <em>ob</em> ein Term der Sentiment-Liste im Corpus vorkam. Genauer ist es, diesen Term mit seinem Sentiment-Wert zu gewichten, also eine gewichtete Summe zu erstellen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sentiment_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">token =</span> Wort) -&gt;<span class="st"> </span>sentiment_df

afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">left_join</span>(sentiment_df, <span class="dt">by =</span> <span class="st">&quot;token&quot;</span>) -&gt;<span class="st"> </span>afd_df 



afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(Wert)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">Sentimentwert =</span> <span class="kw">sum</span>(Wert, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)) -&gt;<span class="st"> </span>afd_sentiment_summe


afd_sentiment_summe$Sentimentwert
<span class="co">#&gt; [1] -23.9</span></code></pre></div>
<p>Zuerst bennenen wir <code>Wort</code> in <code>token</code> um, damit es beiden Dataframes (<code>sentiment_df</code> und <code>afd_df</code>) eine Spalte mit gleichen Namen gibt. Diese Spalte können wir dann zum “Verheiraten” (<code>left_join</code>) der beiden Spalten nutzen. Dann summieren wir den Sentiment-Wert jeder nicht-leeren Zeile auf.</p>
<p>Siehe da: Nun ist der Duktus deutlich negativer als positiver. Offebar werden mehr positive Wörter als negative verwendet, <em>aber</em> die negativen sind viel intensiver.</p>
</div>
<div id="tokens-mit-den-extremsten-sentimentwerten" class="section level3">
<h3><span class="header-section-number">8.3.4</span> Tokens mit den extremsten Sentimentwerten</h3>
<p>Schauen wir uns die intensivesten Wörter mal an.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(neg_pos ==<span class="st"> &quot;pos&quot;</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">distinct</span>(token, <span class="dt">.keep_all =</span> <span class="ot">TRUE</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(-Wert) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">row_number</span>() &lt;<span class="st"> </span><span class="dv">11</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(token, Wert) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">token</th>
<th align="right">Wert</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">besonders</td>
<td align="right">0.539</td>
</tr>
<tr class="even">
<td align="left">genießen</td>
<td align="right">0.498</td>
</tr>
<tr class="odd">
<td align="left">wichtig</td>
<td align="right">0.382</td>
</tr>
<tr class="even">
<td align="left">sicher</td>
<td align="right">0.373</td>
</tr>
<tr class="odd">
<td align="left">helfen</td>
<td align="right">0.373</td>
</tr>
<tr class="even">
<td align="left">miteinander</td>
<td align="right">0.370</td>
</tr>
<tr class="odd">
<td align="left">groß</td>
<td align="right">0.369</td>
</tr>
<tr class="even">
<td align="left">wertvoll</td>
<td align="right">0.357</td>
</tr>
<tr class="odd">
<td align="left">motiviert</td>
<td align="right">0.354</td>
</tr>
<tr class="even">
<td align="left">gepflegt</td>
<td align="right">0.350</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
afd_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(neg_pos ==<span class="st"> &quot;neg&quot;</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">distinct</span>(token, <span class="dt">.keep_all =</span> <span class="ot">TRUE</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(Wert) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">row_number</span>() &lt;<span class="st"> </span><span class="dv">11</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(token, Wert) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">token</th>
<th align="right">Wert</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">schädlich</td>
<td align="right">-0.927</td>
</tr>
<tr class="even">
<td align="left">schwach</td>
<td align="right">-0.921</td>
</tr>
<tr class="odd">
<td align="left">brechen</td>
<td align="right">-0.799</td>
</tr>
<tr class="even">
<td align="left">ungerecht</td>
<td align="right">-0.784</td>
</tr>
<tr class="odd">
<td align="left">behindern</td>
<td align="right">-0.775</td>
</tr>
<tr class="even">
<td align="left">falsch</td>
<td align="right">-0.762</td>
</tr>
<tr class="odd">
<td align="left">gemein</td>
<td align="right">-0.720</td>
</tr>
<tr class="even">
<td align="left">gefährlich</td>
<td align="right">-0.637</td>
</tr>
<tr class="odd">
<td align="left">verbieten</td>
<td align="right">-0.629</td>
</tr>
<tr class="even">
<td align="left">vermeiden</td>
<td align="right">-0.526</td>
</tr>
</tbody>
</table>
<p>Tatsächlich erscheinen die negativen Wörter “dampfender” und “fauchender” als die positiven.</p>
<p>Die Syntax kann hier so übersetzt werden:</p>
<blockquote>
<p>Nehmen den Dataframe adf_df UND DANN<br />
filtere die Token mit negativen Sentiment UND DANN<br />
lösche doppelte Zeilen UND DANN<br />
sortiere (absteigend) UND DANN<br />
filtere nur die Top 10 UND DANN<br />
zeige nur die Saplten token und Wert UND DANN<br />
zeige eine schöne Tabelle.</p>
</blockquote>
</div>
<div id="relativer-sentiments-wert" class="section level3">
<h3><span class="header-section-number">8.3.5</span> Relativer Sentiments-Wert</h3>
<p>Nun könnte man noch den erzielten “Netto-Sentimentswert” des Corpus ins Verhältnis setzen Sentimentswert des Lexikons: Wenn es insgesamt im Sentiment-Lexikon sehr negativ zuginge, wäre ein negativer Sentimentwer in einem beliebigen Corpus nicht überraschend.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
sentiment_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(Wert)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>() +
<span class="st">  </span><span class="kw">aes</span>(<span class="dt">x =</span> Wert) +
<span class="st">  </span><span class="kw">geom_histogram</span>()</code></pre></div>
<p><img src="09_Textmining_files/figure-html/unnamed-chunk-24-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Es scheint einen (leichten) Überhang an negativen Wörtern zu geben. Schauen wir auf die genauen Zahlen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sentiment_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(Wert)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">count</span>(neg_pos)
<span class="co">#&gt; # A tibble: 2 × 2</span>
<span class="co">#&gt;   neg_pos     n</span>
<span class="co">#&gt;     &lt;chr&gt; &lt;int&gt;</span>
<span class="co">#&gt; 1     neg  1818</span>
<span class="co">#&gt; 2     pos  1650</span></code></pre></div>
<p>Tatsächlich ist die Zahl negativ konnotierter Terme etwas größer als die Zahl der positiv konnotierten. Jetzt gewichten wir die Zahl mit dem Sentimentswert der Terme, in dem wir die Sentimentswerte (die ein negatives bzw. ein positives Vorzeichen aufweisen) aufaddieren.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sentiment_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(!<span class="kw">is.na</span>(Wert)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">sentiment_summe =</span> <span class="kw">sum</span>(Wert)) -&gt;<span class="st"> </span>sentiment_lexikon_sum

sentiment_lexikon_sum$sentiment_summe
<span class="co">#&gt; [1] -187</span></code></pre></div>
<p>Im Vergleich zum Sentiment der Lexikons ist unser Corpus deutlich negativer. Um genau zu sein, um diesen Faktor:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sentiment_lexikon_sum$sentiment_summe /<span class="st"> </span>afd_sentiment_summe$Sentimentwert
<span class="co">#&gt; [1] 7.83</span></code></pre></div>
<p>Der <em>relative Sentimentswert</em> (relativ zum Sentiment-Lexikon) beträgt also ~7.8.</p>
</div>
</div>
<div id="verknupfung-mit-anderen-variablen" class="section level2">
<h2><span class="header-section-number">8.4</span> Verknüpfung mit anderen Variablen</h2>
<p>Kann man die Textdaten mit anderen Daten verknüpfen, so wird die Analyse reichhaltiger. So könnte man überprüfen, ob sich zwischen Sentiment-Gehalt und Zeit oder Autor ein Muster findet/bestätigt. Uns liegen in diesem Beispiel keine andere Daten vor, so dass wir dieses Beispiel nicht weiter verfolgen.</p>
<hr />
</div>
<div id="vertiefung" class="section level2">
<h2><span class="header-section-number">8.5</span> Vertiefung</h2>
<div id="erstellung-des-sentiment-lexikons" class="section level3">
<h3><span class="header-section-number">8.5.1</span> Erstellung des Sentiment-Lexikons</h3>
<p>Der Zweck dieses Abschnitts ist es, eine Sentiment-Lexikon in deutscher Sprache einzulesen.</p>
<p>Dazu wird das Sentiment-Lexikon <a href="http://asv.informatik.uni-leipzig.de/download/sentiws.html">dieser Quelle</a> verwendet (CC-BY-NC-SA 3.0). In <a href="http://asv.informatik.uni-leipzig.de/publication/file/155/490_Paper.pdf">diesem Paper</a> finden sich Hintergründe. Von dort lassen sich die Daten herunter laden. Im folgenden gehe ich davon aus, dass die Daten herunter geladen sind und sich im Working Directory befinden.</p>
<p>Wir benötigen diese Pakete (es ginge auch über base):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(stringr)
<span class="kw">library</span>(readr)
<span class="kw">library</span>(dplyr)</code></pre></div>
<p>Dann lesen wir die Daten ein, zuerst die Datei mit den negativen Konnotationen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">neg_df &lt;-<span class="st"> </span><span class="kw">read_tsv</span>(<span class="st">&quot;SentiWS_v1.8c_Negative.txt&quot;</span>, <span class="dt">col_names =</span> <span class="ot">FALSE</span>)
<span class="kw">names</span>(neg_df) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Wort_POS&quot;</span>, <span class="st">&quot;Wert&quot;</span>, <span class="st">&quot;Inflektionen&quot;</span>)

<span class="kw">glimpse</span>(neg_df)</code></pre></div>
<p>Dann parsen wir aus der ersten Spalte (<code>Wort_POS</code>) zum einen den entsprechenden Begriff (z.B. “Abbau”) und zum anderen die Wortarten-Tags (eine Erläuterung zu den Wortarten-Tags findet sich <a href="http://www.jlcl.org/2013_Heft1/H2013-1.pdf">hier</a>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
neg_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Wort =</span> <span class="kw">str_sub</span>(Wort_POS, <span class="dv">1</span>, <span class="kw">regexpr</span>(<span class="st">&quot;</span><span class="ch">\\</span><span class="st">|&quot;</span>, .$Wort_POS)-<span class="dv">1</span>),
         <span class="dt">POS =</span> <span class="kw">str_sub</span>(Wort_POS, <span class="dt">start =</span> <span class="kw">regexpr</span>(<span class="st">&quot;</span><span class="ch">\\</span><span class="st">|&quot;</span>, .$Wort_POS)+<span class="dv">1</span>)) -&gt;<span class="st"> </span>neg_df</code></pre></div>
<p><code>str_sub</code> parst zuerst das Wort. Dazu nehmen wir den Wort-Vektor <code>Wort_POS</code>, und für jedes Element wird der Text von Position 1 bis vor dem Zeichen <code>|</code> geparst; da der Querstrich ein Steuerzeichen in Regex muss er escaped werden. Für <code>POS</code> passiert das gleiche von Position <code>|</code>+1 bis zum Ende des Text-Elements.</p>
<p>Das gleiche wiederholen wir für positiv konnotierte Wörter.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pos_df &lt;-<span class="st"> </span><span class="kw">read_tsv</span>(<span class="st">&quot;SentiWS_v1.8c_Positive.txt&quot;</span>, <span class="dt">col_names =</span> <span class="ot">FALSE</span>)
<span class="kw">names</span>(pos_df) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Wort_POS&quot;</span>, <span class="st">&quot;Wert&quot;</span>, <span class="st">&quot;Inflektionen&quot;</span>)
pos_df %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Wort =</span> <span class="kw">str_sub</span>(Wort_POS, <span class="dv">1</span>, <span class="kw">regexpr</span>(<span class="st">&quot;</span><span class="ch">\\</span><span class="st">|&quot;</span>, .$Wort_POS)-<span class="dv">1</span>),
         <span class="dt">POS =</span> <span class="kw">str_sub</span>(Wort_POS, <span class="dt">start =</span> <span class="kw">regexpr</span>(<span class="st">&quot;</span><span class="ch">\\</span><span class="st">|&quot;</span>, .$Wort_POS)+<span class="dv">1</span>)) -&gt;<span class="st"> </span>pos_df</code></pre></div>
<p>Schließlich schweißen wir beide Dataframes in einen:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bind_rows</span>(<span class="st">&quot;neg&quot;</span> =<span class="st"> </span>neg_df, <span class="st">&quot;pos&quot;</span> =<span class="st"> </span>pos_df, <span class="dt">.id =</span> <span class="st">&quot;neg_pos&quot;</span>) -&gt;<span class="st"> </span>sentiment_df
sentiment_df %&gt;%<span class="st"> </span><span class="kw">select</span>(neg_pos, Wort, Wert, Inflektionen, -Wort_POS) -&gt;<span class="st"> </span>sentiment_df</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr::<span class="kw">kable</span>(<span class="kw">head</span>(sentiment_df))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">neg_pos</th>
<th align="left">token</th>
<th align="right">Wert</th>
<th align="left">Inflektionen</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">neg</td>
<td align="left">Abbau</td>
<td align="right">-0.058</td>
<td align="left">Abbaus,Abbaues,Abbauen,Abbaue</td>
</tr>
<tr class="even">
<td align="left">neg</td>
<td align="left">Abbruch</td>
<td align="right">-0.005</td>
<td align="left">Abbruches,Abbrüche,Abbruchs,Abbrüchen</td>
</tr>
<tr class="odd">
<td align="left">neg</td>
<td align="left">Abdankung</td>
<td align="right">-0.005</td>
<td align="left">Abdankungen</td>
</tr>
<tr class="even">
<td align="left">neg</td>
<td align="left">Abdämpfung</td>
<td align="right">-0.005</td>
<td align="left">Abdämpfungen</td>
</tr>
<tr class="odd">
<td align="left">neg</td>
<td align="left">Abfall</td>
<td align="right">-0.005</td>
<td align="left">Abfalles,Abfälle,Abfalls,Abfällen</td>
</tr>
<tr class="even">
<td align="left">neg</td>
<td align="left">Abfuhr</td>
<td align="right">-0.337</td>
<td align="left">Abfuhren</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Silge2016">
<p>Silge, Julia, and David Robinson. 2016. “Tidytext: Text Mining and Analysis Using Tidy Data Principles in R.” <em>The Journal of Open Source Software</em> 1 (3). The Open Journal. doi:<a href="https://doi.org/10.21105/joss.00037">10.21105/joss.00037</a>.</p>
</div>
<div id="ref-remquahey2010">
<p>Remus, R., U. Quasthoff, and G. Heyer. 2010. “SentiWS – a Publicly Available German-Language Resource for Sentiment Analysis.” In <em>Proceedings of the 7th International Language Resources and Evaluation (Lrec’10)</em>, 1168–71.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="28">
<li id="fn28"><p>Dank an Karsten Lübke, dessen Fachkompetenz mir mindestens so geholfen hat wie seine Begeisterung an der Statistik ansteckend ist.<a href="textmining.html#fnref28">↩</a></p></li>
<li id="fn29"><p>Nach dem Gedicht “Jahrgang 1899” von Erich Kästner<a href="textmining.html#fnref29">↩</a></p></li>
<li id="fn30"><p><a href="https://www.alternativefuer.de/wp-content/uploads/sites/7/2016/05/2016-06-27_afd-grundsatzprogramm_web-version.pdf" class="uri">https://www.alternativefuer.de/wp-content/uploads/sites/7/2016/05/2016-06-27_afd-grundsatzprogramm_web-version.pdf</a><a href="textmining.html#fnref30">↩</a></p></li>
<li id="fn31"><p><a href="http://www.omegahat.net/Rstem/stemming.pdf" class="uri">http://www.omegahat.net/Rstem/stemming.pdf</a><a href="textmining.html#fnref31">↩</a></p></li>
<li id="fn32"><p><a href="https://cran.r-project.org/web/packages/wordcloud/index.html" class="uri">https://cran.r-project.org/web/packages/wordcloud/index.html</a><a href="textmining.html#fnref32">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="klassifizierende-modelle.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ergebnisse-kommunizieren.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
